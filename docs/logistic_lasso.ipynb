{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f35a2ee",
   "metadata": {},
   "source": [
    "# Logistic Lasso Selective Inference Example\n",
    "\n",
    "This notebook demonstrates how to perform selective inference after fitting a logistic lasso model. \n",
    "We will generate some synthetic data, use the bootstrap to estimate the covariance of the unpenalized score, and finally compute post-selection confidence intervals and p-values for the parameters.\n",
    "\n",
    "## Setup Data and Bootstrap\n",
    "\n",
    "We start by generating a dataset of $n=300$ observations and $p=10$ features, where only the first few features are truly active. Then, we approximate the variance of the unpenalized score $Z_{full} = Q \\bar{\\beta}$ via the bootstrap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c20f35be-1f75-463b-a81e-7e80a3971148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "\n",
    "# 1. Generate data\n",
    "np.random.seed(42)\n",
    "n, p = 500, 20\n",
    "X = np.random.randn(n, p)\n",
    "\n",
    "true_beta = np.zeros(p)\n",
    "true_beta[:3] = [2.0, -2.0, 1.0]\n",
    "\n",
    "logits = X @ true_beta\n",
    "probs = expit(logits)\n",
    "y = np.random.binomial(1, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1e746d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running bootstrap...\n",
      "Bootstrap finished.\n"
     ]
    }
   ],
   "source": [
    "# 2. Estimate Sigma via bootstrap\n",
    "B = 30\n",
    "Z_boot = []\n",
    "\n",
    "print(\"Running bootstrap...\")\n",
    "for b in range(B):\n",
    "    indices = np.random.choice(n, n, replace=True)\n",
    "    X_b, y_b = X[indices], y[indices]\n",
    "    \n",
    "    # Unpenalized logistic fit\n",
    "    beta_b = cp.Variable(p)\n",
    "    loss_b = cp.sum(\n",
    "        cp.logistic(X_b @ beta_b) - cp.multiply(y_b, X_b @ beta_b)\n",
    "    )\n",
    "    prob_b = cp.Problem(cp.Minimize(loss_b))\n",
    "    \n",
    "    # Using SCS solver for reliability here\n",
    "    prob_b.solve(solver=cp.SCS)\n",
    "    \n",
    "    if beta_b.value is None:\n",
    "        continue\n",
    "        \n",
    "    b_val = beta_b.value\n",
    "    p_b = expit(X_b @ b_val)\n",
    "    W_b = np.diag(p_b * (1 - p_b))\n",
    "    Q_b = X_b.T @ W_b @ X_b\n",
    "    Z_b = Q_b @ b_val\n",
    "    \n",
    "    Z_boot.append(Z_b)\n",
    "\n",
    "Z_boot = np.array(Z_boot)\n",
    "Sigma = np.cov(Z_boot, rowvar=False)\n",
    "print(\"Bootstrap finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006861e6",
   "metadata": {},
   "source": [
    "## Fitting the Unpenalized and Penalized Models\n",
    "\n",
    "We now fit the unpenalized model on the original data to obtain $Z_{full}$, which acts as the target for our inference. Then, we simulate a \"noisy\" experiment by selecting a random bootstrap sample to act as our dataset for selection. We fit the lasso penalty on this sample to choose our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b45bb261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Unpenalized fit on full data\n",
    "beta_orig = cp.Variable(p)\n",
    "loss_orig = cp.sum(\n",
    "    cp.logistic(X @ beta_orig) - cp.multiply(y, X @ beta_orig)\n",
    ")\n",
    "prob_orig = cp.Problem(cp.Minimize(loss_orig))\n",
    "prob_orig.solve(solver=cp.SCS)\n",
    "\n",
    "bar_beta = beta_orig.value\n",
    "p_orig = expit(X @ bar_beta)\n",
    "W_orig = np.diag(p_orig * (1 - p_orig))\n",
    "Q_full = X.T @ W_orig @ X\n",
    "\n",
    "# Target statistic Z_full\n",
    "Z_full = Q_full @ bar_beta\n",
    "\n",
    "# 4. \"Noisy\" example: selection on a bootstrap sample\n",
    "indices_noisy = np.random.choice(n, n, replace=True)\n",
    "X_noisy, y_noisy = X[indices_noisy], y[indices_noisy]\n",
    "\n",
    "beta_lasso = cp.Variable(p)\n",
    "lam = 7.0 # L1 penalty\n",
    "D_weight = lam * np.ones(p)\n",
    "D_weight[2] = 0.0 # 3rd feature unpenalized\n",
    "\n",
    "loss_noisy = cp.sum(\n",
    "    cp.logistic(X_noisy @ beta_lasso) - cp.multiply(y_noisy, X_noisy @ beta_lasso)\n",
    ")\n",
    "penalty = cp.sum(cp.multiply(D_weight, cp.abs(beta_lasso)))\n",
    "constraints = [\n",
    "    beta_lasso[0] >= -2.0,\n",
    "    beta_lasso[0] <= 2.0,\n",
    "    beta_lasso[1] >= 0.0\n",
    "]\n",
    "prob_lasso = cp.Problem(cp.Minimize(loss_noisy + penalty), constraints)\n",
    "prob_lasso.solve(solver=cp.SCS)\n",
    "\n",
    "beta_hat = beta_lasso.value\n",
    "\n",
    "# Post-selection quantities\n",
    "p_noisy = expit(X_noisy @ beta_hat)\n",
    "G_hat = -X_noisy.T @ (y_noisy - p_noisy)\n",
    "W_noisy = np.diag(p_noisy * (1 - p_noisy))\n",
    "Q_hat = X_noisy.T @ W_noisy @ X_noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ed62b3",
   "metadata": {},
   "source": [
    "## Post-Selection Inference\n",
    "\n",
    "With all ingredients gathered, we can pass the selection parameters, original constraints, and statistics into `LassoInference`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12140c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>beta_hat</th>\n",
       "      <th>lower_conf</th>\n",
       "      <th>upper_conf</th>\n",
       "      <th>p_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.818694</td>\n",
       "      <td>0.406574</td>\n",
       "      <td>0.427192</td>\n",
       "      <td>0.005294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.548266</td>\n",
       "      <td>0.161210</td>\n",
       "      <td>0.166242</td>\n",
       "      <td>0.001111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.028096</td>\n",
       "      <td>-0.041383</td>\n",
       "      <td>-0.036949</td>\n",
       "      <td>0.414955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.245668</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.007833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>0.300697</td>\n",
       "      <td>0.042705</td>\n",
       "      <td>0.046061</td>\n",
       "      <td>0.312374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.034384</td>\n",
       "      <td>0.034384</td>\n",
       "      <td>0.006567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.096061</td>\n",
       "      <td>0.052657</td>\n",
       "      <td>0.055486</td>\n",
       "      <td>0.191781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  beta_hat  lower_conf  upper_conf   p_value\n",
       "0      0  0.818694    0.406574    0.427192  0.005294\n",
       "1      2  0.548266    0.161210    0.166242  0.001111\n",
       "2      4 -0.028096   -0.041383   -0.036949  0.414955\n",
       "3      5  0.245668    0.099600    0.099600  0.007833\n",
       "4      7  0.300697    0.042705    0.046061  0.312374\n",
       "5      8 -0.000001    0.034384    0.034384  0.006567\n",
       "6      9  0.096061    0.052657    0.055486  0.191781"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lassoinf.selective_inference import LassoInference\n",
    "\n",
    "D = D_weight\n",
    "L_bound = np.full(p, -np.inf)\n",
    "L_bound[0] = -2.0\n",
    "L_bound[1] = 0.0\n",
    "\n",
    "U_bound = np.full(p, np.inf)\n",
    "U_bound[0] = 2.0\n",
    "\n",
    "# 5. Inference\n",
    "inference = LassoInference(\n",
    "    beta_hat=beta_hat,\n",
    "    G_hat=G_hat,\n",
    "    Q_hat=Q_hat,\n",
    "    D=D,\n",
    "    L=L_bound,\n",
    "    U=U_bound,\n",
    "    Z_full=Z_full,\n",
    "    Sigma=Sigma,\n",
    "    Sigma_noisy=Sigma  # Re-use bootstrap covariance\n",
    ")\n",
    "\n",
    "# 6. View the summary of free (selected) variables\n",
    "summary_df = inference.summary()\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52d5ad-b168-4a20-b750-1ea5d0275036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "default_lexer": "ipython3",
   "formats": "ipynb,md:myst",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

\documentclass{article}

\input{../preamble.sty}
\usepackage{lmodern}

\newcommand{\ag}[1]{{\bf{{\red{[{AG: #1}]}}}}}
\newcommand{\InnerProduct}[2]{\langle #1,#2 \rangle}
\newcommand{\Norm}[1]{\|#1\|}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\br}{{\bf r}}
\newcommand{\bs}{{\bf s}}
\newcommand{\bt}{{\boldsymbol t}}
\newcommand{\bH}{{\boldsymbol H}}
\newcommand{\Newton}{\mathrm{Newton}}
\newcommand{\DummyField}{{\tt f}}
\newcommand{\DummyGradient}{{\bf g}}
\newcommand{\InformationMatrix}{{\boldsymbol J}}
\newcommand{\lin}{\mathrm{lin}}
\newcommand{\ind}{\perp\!\!\!\!\perp} 
\newcommand{\Exp}{\mathrm{Exp}}

\newcommand{\RandomField}{Y}
\newcommand{\bLambda}{{\boldsymbol \Lambda}}
\newcommand{\bGamma}{{\boldsymbol \Gamma}}
\newcommand{\Err}{\mathrm{Err}}
\newcommand{\bQ}{{\boldsymbol Q}}
\newcommand{\bJ}{{\boldsymbol J}}
\newcommand{\bV}{{\boldsymbol V}}
\newcommand{\bI}{{\boldsymbol I}}
\newcommand{\bC}{{\boldsymbol C}}
\newcommand{\convweak}{\overset{d}{\to}}

\newcommand{\appropto}{\mathrel{\vcenter{
			\offinterlineskip\halign{\hfil$##$\cr
				\propto\cr\noalign{\kern2pt}\sim\cr\noalign{\kern-2pt}}}}}

\renewcommand{\thealgorithm}{\arabic{algorithm}}

\title{ {\bf Inference for Local Maxima of a Gaussian Random Field} \\ Efron Hinkley statistics}

\begin{document}

	\maketitle
	\RaggedRight

\section{An attempt}

I'm going to attempt to motivate a definition of Efron Hinkley statistics (which generally
won't be ancillary).

My data is $Z \sim N(\theta^*, I)$, my bundle is $T^*(\R^n)$ and my process is
$$
\sum_{i=1}^n a_i(x) \frac{\partial}{\partial x_i} \biggl|_x = \sum_{i=1}^n a_i(x)(Z_i - x_i) \overset{def}{=} \xi \left(\sum_{i=1}^n a_i \frac{\partial}{\partial x_i}\right)_x.
$$
This is a well-defined random section of $T^*(\R^n)$. In this case, because my covariance
is non-degenerate $H=T^*(\R^n)$ and the Riemannian metric it inherits (because $H$ is
a co-tangent bundle) is just the Euclidean matric.

On $\R^n$ this process has a Kac-Rice intensity on $\R^n$ given by counting
$$
\left\{x \in \R^n: \xi_x=0\}.
$$
It will just be $(2\pi)^{-n/2} e^{-\|x-\theta\|^2_2/2}$.

I want to restrict this section
to a sub-bundle of $T^*(R^n)$, by taking an embedded submanifold  $M \subset \R^n$ and restrict $\xi$ to $T^*(M)$. The construction for restriction described in the abstract nonsense goes as follows.
Pick an orthonormal frame field on $H$, say $\omega_1, \dots, \omega_n$ and, without
loss of generality we'll kill off the last $k$ components. That is, set
$$
\text{span}(\omega_{1,x}, \dots, \omega_{n-k,x}) \subset T_x\R^n (=T_x^*\R^n)
$$
and define the restricted process $\bar{\xi}$ as
$$
\begin{aligned}
\bar{\xi}\left(\sum_{i=1}^n a_i \frac{\partial}{\partial x_i}\right)_x &=
\sum_{i=1}^{n-k} \omega_i \left(\sum_{i=1}^n a_i \frac{\partial}{\partial x_i}\right)_x 
\xi(\omega_i)_x
\end{aligned}
$$
with
$$
\xi(\omega_i)_x = \sum_{j=1}^n \omega_{i,j,x} (Z_j-x_j)
$$
and
$$
\omega_{i,x} = \sum_{j=1}^n \omega_{i,j,x} \frac{\partial}{\partial x_j} \biggl|_x.
$$
If $M$ is co-dimension $k$, then we can pick our frame so that
$$(\eta_1, \dots, \eta_k) \overset{def}{=} (\omega_{n-k+1}, \dots, \omega_n)$$
are orthonormal frames on $N(M)$. I.e. for each $x$ they form an orthonormal basis for
$N_xM$ the ortho-complement of $T_xM$ in $T_x\R^n$.

When $\bar{\xi}$ is restricted to $M$ it will generically get a Kac-Rice intensity. It should be
clear here that this is counting
$$
\left\{x \in M: \xi(\omega_i)_x=0, 1 \leq i \leq n-k\right\}
$$
As the first $n-k$ forms span $T_xM$  this process counts zeros of the score in $M$, i.e.
solutions to
\begin{equation}
\label{eq:critical:set}
\left\{x: X_x(Z-x)=0 \ \forall \  X_x \in T_xM\right\}.
\end{equation}
This of course corresponds to critical points of the restriction of  to $M$ of the function
$$
x \mapsto \frac{1}{2}\|Z-x\|^2_2.
$$

\subsection{Efron-Hinkley section}

The {\bf EH section} is the random section of $T_x^*\R^n$ given by
$$
\sum_{l=n-k+1}^n \omega_l(\xi)_x \omega_l
\sum_{i=1}^k \eta_i(\xi)_x \eta_i = \sum_{i=1}^k \sum_{j=1}^n \eta_{i,j}(x)(Z_j - x_j) \frac{\partial}{\partial x_j} \biggl|_x
$$
where
$$
\eta_i(x) = \sum_{j=1}^n \eta_{i,j}(x) \frac{\partial}{\partial x_j} \biggl|_x.
$$
Having fixed our frame the EH section determines an $\R^k$ valued random field on $M$. Its values at any point can be observed. In particular its values at a point where $\bar{\xi}_x=0$
are well-defined. This associates an Efron-Hinkley statistic in $\R^k$, observable at any point in \eqref{eq:critical:set}, making the critical set a marked point process with marks in
$\R^k$.

\subsection{Second fundamental form}

What is the second fundamental form of $M \subset \R^n$? It is a
tensor field on $N(M) \otimes T(M) \otimes T(M)$. That is, for any
triple $N_x \in V_x \in N_xM, X_x \in T_xM, Y_x \in T_xM$ it yields a
number. Picking any basis for $N_x$ (of dimension $k$) and any
basis for $T_xM$ it can be
described by $k$ fixed matrices of size $(d-k) \times (d-k)$. We might
as well pick our basis of $N_xM$ to be $(\eta_{1,x}, \dots, \eta_{k,x})$
and our basis of $T_xM$ to be $(\omega_{1,x}, \dots, \omega_{n-k}(x))$.
Call these matrices
Call them $S_{i,x}, 1 \leq i \leq k$. These are non-random $(n-k) \times (n-k)$ matrix valued functions on
$M$.

Now, the second fundamental form can be computed in any direction
$$
N_xM \ni V_x = \sum_{i=1}^k v_{i,x} \eta_{i,x}
$$ and {\em any} pair $X_x,Y_x \in T_xM$ simply by knowing the sum
$$
\sum_{i=1}^k v_{i,x} S_{i,x}.
$$
Specifically, we'd have to write $X_x, Y_x$ in terms of our chosen basis but that's not much work. In short, to be able to compute the second fundamental form in the direction $V_x$ in {\em any} pair of tangent
directions it suffices to know the coefficients of $V_x$ in our chosen (non-random) basis. That is, it suffices to know the numbers
$$
v_{i,x} = \eta_{i,x}(V_x).
$$

Now, at a point in \eqref{eq:critical:set} the first order conditions imply
$$
Z-x \in N_xM.
$$
Its coefficients in our chosen basis are the quantities $\eta_{i,x}(Z-x)$. These are the marks
in our marked point process: the EH statistic associated to the critical point $x$. Hence, conditioning on $\eta_{i,x}(Z-x)$ is equivalent to conditioning on 
$$
\sum_{i=1}^k \eta_{i,x}(Z-x) S_{i,x}.
$$
This is the second fundamental form of $M$ as it sits in $\R^n$ in the (random direction) $P_{N_xM}(Z-x)$.

\subsection{Is EH ancillary?}

The random variables $(\eta_{i,x}(Z-x))$ are statistics but they are not ancillary.
Suppose $M$ is a linear subspace of $\R^n$ and $\theta^*$ so $\eta_{i,x}(x)=0$.
Then, at any given $x$ we have
$$
EH_i = \eta_{i,x}(Z-x) \sum N(\eta_i(\theta^*), 1)
$$

The random variables
$$
W_i = \eta_{i,x}(Z-\theta^*-x) \sim N(0, 1)
$$
are ancillary in the sense their distribution is known, but they are not ancillary.

\subsection{Can they be conditioned on?}

Yes. The Kac-Rice intensity of $\xi$ is a function on $\R^n$. It can be evaluated in
a coordinate system locally on $M$ with its first $k$-coordinates given by coefficients
in the $\eta_i$'s and some coordinate system on $T_xM$. To condition on the
EH statistic, we fix the first $k$ coordinates of this joint intensity.

\subsection{Do they need to be standardized?}

No, we don't need orthonormal frames: the matrices $S_{i,x}$ would still be well-defined, though they would depend on inner products of vectors in our basis for $N_xM$ and $T_xM$. We must of course have these bases are pairwise orthogonal (so that they are genuine bases for $N_xM$ and $T_xM$ with the metric inherited from $\xi$).

\end{document}

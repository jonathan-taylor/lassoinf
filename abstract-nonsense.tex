\documentclass{article}

\input{../preamble.sty}
\usepackage{lmodern}

\newcommand{\ag}[1]{{\bf{{\red{[{AG: #1}]}}}}}
\newcommand{\jt}[1]{{\bf{{\red{[{JT: #1}]}}}}}
\newcommand{\InnerProduct}[2]{\langle #1,#2 \rangle}
\newcommand{\Norm}[1]{\|#1\|}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\br}{{\bf r}}
\newcommand{\bs}{{\bf s}}
\newcommand{\bt}{{\boldsymbol t}}
\newcommand{\bH}{{\boldsymbol H}}
\newcommand{\Newton}{\mathrm{Newton}}
\newcommand{\DummyField}{{\tt f}}
\newcommand{\DummyGradient}{{\bf g}}
\newcommand{\InformationMatrix}{{\boldsymbol J}}
\newcommand{\lin}{\mathrm{lin}}
\newcommand{\ind}{\perp\!\!\!\!\perp} 
\newcommand{\Exp}{\mathrm{Exp}}

\newcommand{\RandomField}{Y}
\newcommand{\bLambda}{{\boldsymbol \Lambda}}
\newcommand{\bGamma}{{\boldsymbol \Gamma}}
\newcommand{\Err}{\mathrm{Err}}
\newcommand{\bQ}{{\boldsymbol Q}}
\newcommand{\bJ}{{\boldsymbol J}}
\newcommand{\bV}{{\boldsymbol V}}
\newcommand{\bI}{{\boldsymbol I}}
\newcommand{\bC}{{\boldsymbol C}}
\newcommand{\convweak}{\overset{d}{\to}}

\newcommand{\appropto}{\mathrel{\vcenter{
			\offinterlineskip\halign{\hfil$##$\cr
				\propto\cr\noalign{\kern2pt}\sim\cr\noalign{\kern-2pt}}}}}

\renewcommand{\thealgorithm}{\arabic{algorithm}}

\title{ {\bf Inference for Local Maxima of a Gaussian Random Field} \\ Abstract nonsense: random sections, zeros, Kac-Rice and Slepian}

\begin{document}

	\maketitle
	\RaggedRight

\section{A dose of abstract nonsense}

In this bit of abstract nonsense, we're going to discuss smooth random
sections of a rank $d$ bundle $\pi:E \to M$ (generalization of smooth random
fields) and associated probabilistic constructs. As in the case of a random field, a random section can
be viewed as a map $\xi:\Omega \to \Gamma(E)$, i.e. a map from a probability space to smooth sections of $E$.
We're going to work with just $C^{\infty}$ for now, as the point is to see what tools are in the toolbox.
We'll assume the existence of $\bar{\nabla}$, a base connection on $E$. The map $\xi$ will determine
its own connection as in the case of a real-valued random field on $M$, the base connection is just to
ensure we have some notion of differentiating sections, though it is not strictly necessary.

\subsection{Canonical example}

Pick a set $\{V_1, \dots, V_n\} \in \Gamma(E)$, i.e. a set of sections of the dual bundle $E$ and
a random vector $\bar{\zeta}:\Omega \rightarrow \mathbb{R}^n$ and define, for any $\alpha_p \in E_p^*$
\begin{equation}
  \label{eq:process}
\alpha_p(\xi(\omega)) = \sum_{i=1}^n \bar{\zeta}_i(\omega) \cdot \alpha(V_i)_p.
\end{equation}
The mean of $\xi$ is clearly
$$
\sum_{i=1}^n \E[\bar{\zeta}_i] \cdot V_i.
$$
If $\bar{\zeta}_i$ are Gaussian this would of course be a smooth Gaussian section of $E$, though
the construction above doesn't require Gaussianity.

As for random fields, there is an associated RKHS. In this case, the covariance kernel is a map $R:E^* \times E^* \to \R$ determined by
$$
R(\alpha_p, \bar{\alpha}_q) = \text{Cov}(\alpha_p(\xi), \bar{\alpha}_q(\xi)), \qquad \alpha_p \in F_p, \bar{\alpha}_q \in F_q.
$$
The corresponding  RKHS is a subspace of $\Gamma(E)$ with witness functions
$$
\langle R_{\alpha_p}, R_{\bar{\alpha}_q} \rangle_{\cH} = R(\alpha_p, \bar{\alpha}_q).
$$
The basic function in the RKHS takes the form
$$
h = \sum_j c_j R_{\alpha_{p_j}}   \in \Gamma(E)
$$
defined by
$$
h(\bar{\alpha})_q = \sum_j c_j R(\alpha_{p_j}, \bar{\alpha}_q)
$$
with the reproducing property following
$$
\langle R_{\alpha_p}, R_{\bar{\alpha}_q} \rangle = R(\alpha_p, \bar{\alpha}_q).
$$

A different, but equivalent way to define a random section of $E$ is as a real valued process $\bar{\xi}:\Omega \times E^* \rightarrow \R$ satisfying
\begin{equation}
  \label{eq:alternate:construction}
\bar{\xi}(\alpha_p + \bar{\alpha}_p) = \bar{\xi}(\alpha_p) + \bar{\alpha}_p).
\end{equation}
Thus, defining any process of the form $\bar{\xi}$ on $E^*$ determines a random section of $E$ via
$$
\xi(\alpha)_p = \bar{\xi}(\alpha_p).
$$

The RKHS also determines a smooth (possibly degenerate) metric on $E^*$ (and hence $E$):
$$
g_p(\alpha_p, \bar{\alpha}_p) = \text{Cov}(\alpha_p(\xi), \bar{\alpha}_p(\xi)).
$$
The subspace on which $g$ is non-degenerate which we might call $H_p$. Assuming the subspaces vary
smoothly may lead to a sub-bundle $H \subset E$ on which the metric would be non-degenerate.
With this metric on $H^* \subset E^*$ we see that there is an equivalent RKHS $\cH^*$ of sections of $\Gamma(E^*)$ via fiberwise
application of the Riesz representation theorem. 

As we've defined the associate RKHS, we make the assumption that $\mu \in \cH$.

\subsection{Gaussian case}

In the case $\bar{\zeta}$ are mean 0 and Gaussian one can take any orthonormal basis
$(\varphi_i)$ of the RKHS along with IID $\zeta_i \sim N(0,1)$ defined above and realize the law $\xi$ as
\begin{equation}
  \label{eq:KL}
\xi(\omega) \overset{D}{=} \sum_i \zeta_i(\omega) \varphi_i + \mu.
\end{equation}
That is, for $\alpha_p \in H_p^*$
$$
\alpha_p(\xi(\omega)) = \sum_i \zeta_i(\omega) \alpha(\varphi_i)_p + \alpha_p(\mu).
$$

\subsubsection{A few practical (?) examples}

Let $f$ be a real-valued Gaussian field on $M$ and set $\xi_p = df_p$. This is a random section of $T^*(M)$. Shortly,
we'll want to discuss how the laws and intensities related to $\xi$ and its zeros vary so that we might make
sense of asymptotic analysis. 

Consider the following process on $T^*(M \times \R)$: given $(X_{a,p}, b_{a,p}) \in T_p M \oplus T_a \R$ set
$$
\bar{\zeta}_{a,p} = df_p(X_{a,p}) + b_{a,p} \cdot (f_p - u).
$$
As this is a real valued process on $T(M \times \R)$ satisfying the required linearity, by our remark
\eqref{eq:alternate:construction} $\bar{\zeta}$ extends to a random section of $T^*(M \times \R)$. Zeros of
this process determine the intensity for critical points and their values.

Finally, given two real-valued processes $f$ and $\bar{f}$ consider a process on $T^*(M \times M)$ determined as follows: given $(X_{p,\bar{p}}, \bar{X}_{p,\bar{p}}) \in T_pM \oplus T_{\bar{p}}M$
set
$$
\bar{\zeta}_{(X_{p,\bar{p}}, \bar{X}_{p,\bar{p}})}(X_{p,\bar{p}}, \bar{X}_{p,\bar{p}}) = df_p(X_{p,\bar{p}}) + d\bar{f}_{\bar{p}}(\bar{X}_{p,\bar{p}}).
$$ If $f=\bar{f}$ then zeros of the above counts pairs of critical
points. By extending to $T^*((M \times \R) \times (M \times \R))$ as
our second example above we see that zeros of this process determine
the intensity for pairs of critical points and their values.

\section{Differentiation}

Given the base connection $\bar{\nabla}$ on $E$, we can clearly define
$$
\bar{\nabla}_X\xi(\omega) = \sum_i \zeta_i(\omega) \bar{\nabla}_X \varphi_i.
$$
This is certainly well-defined if the RKHS is finite-dimensional. There is, however, a more natural
connection to consider.

\subsection{The ${\cal H}$ connection $\nabla^{\cal H}$}

The RKHS {\em almost} induces a connection $\nabla=\nabla^{\cH}$ on $\Gamma(E)$  in a canonical fashion.
It induces a connection defined on $\cH \subset \Gamma(E)$.
Fix a curve $\gamma:(-\epsilon,\epsilon) \to M$ with $\gamma(0)=p, \dot{\gamma}(0)=X_p$
and consider sections of the form
$p \mapsto R_{\alpha_p} \in F_p$. We first differentiate the curve $R_{\alpha} \circ \gamma$:
\begin{equation}
\dot{R}_{\alpha} = \frac{d}{dt} R_{\alpha} \circ \gamma(t) \biggl|_{t=0} = \lim_{t \to 0} \frac{1}{t} \left[ R_{\alpha(\gamma(t))} - R_{\alpha(0)}\right] \in {\cal H}.
\end{equation}
We then set
$$
\nabla_{X_p}R_{\alpha} = \dot{R}_{\alpha} - P(\dot{R}_{\alpha}, \text{span}(\dot{R}_{\bar{\alpha}_p}, \bar{\alpha}_p \in F_p^*)).
$$
That is, $\nabla_{X_p}R_{\alpha}$ is the residual after projecting $\dot{R}_{\alpha}$ onto the subspace of ${\cal H}$ spanned by the fiber $F_p$.
This connection can therefore be extended to all of ${\cal H}$ in a natural fashion.
Formally, this connection is not defined for any section as we've only defined it on $\cH$. By Riesz
representation,
it is also well defined on $\cH^*$. This is not too worrying as the main use for this connection is to define pathwise derivatives of $\xi$ which only require
${\cal H}$. In turn this allows us to define
a pathwise derivative $\nabla_{X_p}\xi$. By construction, we will have $\nabla_{X_p}\xi$ is orthogonal
to $\alpha_p(\xi)$ for all $\alpha_p \in F_p^*$.

This connection is clearly not the same as the base connection, nor
does it even depend on $\bar{\nabla}$ in any way. We can realize this pathwise derivative by
taking any basis $(\bar{\alpha}_{j,p})$ for $F_p^*$:
\begin{equation}
\label{eq:pathwise:1}
(\nabla_X\xi)_p = (\bar{\nabla}_X\xi)_p - \text{Cov}(\bar{\nabla}_X\xi)_p, \bar{\alpha}_{i,p}(\xi))
  \Sigma^{\dagger}_{ij,p} \bar{\alpha}_{j,p}(\xi)
\end{equation}
with $\Sigma_{ij,p} = \text{Cov}(\bar{\alpha}_{i,p}(\xi),
\bar{\alpha}_{j,p}(\xi))$ with $\Sigma^{\dagger}$ its pseudo-inverse.
This can be checked by using the Karhunen-Lo\'eve expansion
\eqref{eq:KL} for the right hand side and verifying that the
covariance of this random variable with any other linear functional of
$\xi$ is equal, through the usual Paley-Wiener map ${\cal I}:{\cal H}
\to L^2(\Omega)$, to the corresponding inner products on ${\cal
  H}$. In fewer words, in the Gaussian case, the right hand side can be written
\begin{equation}
  \label{eq:pathwise:2}
(\nabla_X\xi)_p(\omega) = {\cal I}(\dot{R}_{\alpha})(\omega) + (\nabla_X \mu)_p
\end{equation}
When $\zeta$ are not Gaussian, ${\cal I}$ is still defined, at least for finite sums.

\subsection{Is it a Levi-Civita connection?}

When $E$ is $T(M)$ or $T^*(M)$ we see that $\cH$ induces (subject to non-degeneracy) a metric on
$E^*$ (and hence $E$). It is therefore a Riemannian metric. We have further associated a
connection to $\cH$. It is natural to ask if this connection is the Levi-Civita connection
of this Riemannian manifold. That is, is it compatible with the metric and torsion free.

In broad generality, the connection $\nabla$ is compatible with the metric on $E^*$.
To see this, let's assuming for the moment that $\mu=0$ below so we can write $\E$ instead of $\Cov$.
For any vector field $X$ and sections $\alpha, \bar{\alpha} \in \cH^*$:
$$
\begin{aligned}
  X(g(\alpha, \bar{\alpha}))_p &= X(\E[\alpha(\xi) \bar{\alpha}(\xi)])_p \\
  &= \E[X(\alpha(\xi))_p \cdot \bar{\alpha}(\xi)_p + \alpha(\xi)_p \cdot X(\bar{\alpha}(\xi))_p] \\
  &= \E\left[\left((\nabla_X\alpha)(\xi)_p + \alpha (\nabla_X\xi)_p\right) \bar{\alpha}(\xi)_p] + \E\left[\alpha(\xi)_p \left((\nabla_X\bar{\alpha})(\xi)_p + \bar{\alpha} (\nabla_X\xi)_p\right) \right] \\
  &= \E\left[(\nabla_X\alpha)(\xi)_p \bar{\alpha}(\xi)_p] + \E\left[\alpha(\xi)_p (\nabla_X\bar{\alpha})(\xi)_p \right] \\
  &= g(\nabla_X\alpha, \bar{\alpha})_p + g(\alpha, \nabla_X\bar{\alpha})_p.
\end{aligned}
$$

The property of being torsion free is less clear. We do note that it is shown that it is indeed
the Levi-Civita connection in \cite{RFG,phdthesis} for
processes $\xi$ of the form $\bar{\xi}_p(X_p)=df_p(X_p)$.

We now resume assuming that $\mu \neq 0$.

\subsection{Higher order derivatives}

We can write the connection $\nabla$ in terms of covariant derivatives
$$
{\nabla} \xi(\omega) = \sum_i \zeta_i(\omega) \nabla \varphi_i \in \Gamma(T^*M \otimes E).
$$
The left hand side is our definition of the pathwise derivative from \eqref{eq:pathwise:2}.  The right
hand side is mathematically valid as $\varphi_i \in {\cal H}$ so we can define $\nabla_X \varphi_i$ as we did
$\nabla_XR_{\alpha}$, extended to linear combinations in the usual fashion.

Higher order covariant derivatives can be similarly defined
$$
\nabla^k \xi(\omega) = \sum_i \zeta_i(\omega) \nabla^k \varphi_i \in \Gamma(T^*M^{\otimes k} \otimes E).
$$

\section{Kac-Rice intensity}

\newcommand{\coordchart}{\mathfrak{t}}

Suppose $\pi:E \to M$ is a vector bundle of rank $d$ on a $d$-dimensional manifold $M$ and $\xi$
a smooth random section of $E$. Then, under standard non-degeneracy assumptions zeros of $\xi$ will be isolated
and we can compute the intensity function of the zeros of $\xi$. As $\cH$ induces a metric on $E$ we can pick
an orthonormal frame for $E^*$ which we denote by $\omega=(\omega_1, \dots, \omega_d) \in \cH^*$ and a chart
$\coordchart:U \to \R^d$ so that
$$
\breve{\xi}_t = (\xi(\omega_1)_{\coordchart^{-1}(t)}, \dots, \xi(\omega_d)_{\coordchart^{-1}(t)}): \R^d \to \R^d.
$$
The standard Kac-Rice formula on $\R^d$ yields, for $B \subset U$
$$
\begin{aligned}
\E \left[\{p \in B: \xi_p=0\} \right] &= \int_{\coordchart(B)} \E\left[|\det(J_t)| \bigr | \breve{\xi}_t=0 \right] \phi_{\breve{\xi}_t}(0) \; dt \\
\end{aligned}
$$
where
$$
\begin{aligned}
  (J_t)_{ij} &= \frac{\partial \breve{\xi}_t}{\partial t_i} \\
  &= (\omega_j(\nabla_{\partial t_i}\xi))_{\coordchart^{-1}(t)} + (\nabla_{\partial t_i} \omega_j)(\xi)_{\coordchart^{-1}(t)}. \\
\end{aligned}
$$
As this the conditional expectation sets $\xi_p$ to 0, we can rewrite this as
$$
\begin{aligned}
\E \left[\{p \in B: \xi_p=0\} \right] &= \int_{\coordchart(B)} \E \left[|\det(\breve{J}_{\coordchart^{-1}(t)})| \bigr | \xi_{\coordchart^{-1}(t)}=0 \right] \phi_{\breve{\xi}_t}(0) \; dt \\
\end{aligned}
$$
with
$$
\begin{aligned}
  (\breve{J}_p)_{ij} &= \omega_j(\nabla_{\partial t_i}\xi)_{p}
\end{aligned}
$$
which is tensorial in $\partial t_i$ and $\omega_j$.

\subsection{Special case: $E=T(M)$ or $E=T^*(M)$}

In this case, as $\cH$ determines a metric on $E^*$ (and $E^*$), this will be a (possibly degenerate) Riemannian
metric. For Kac-Rice it would have to be non-degenerate so the dimension of each fiber is $d$. The implication
here means that the $\omega_j$'s can therefore be interpreted as an orthonormal frame of vector fields with
this metric. The tensorial aspect of $\breve{J}_p$ implies we can now compute this intensity
with respect to the Riemannian measure $\nu$:
$$
\begin{aligned}
\E \left[\{p \in B: \xi_p=0\} \right] &= \int_{B} \E[|\det(\bar{J}_p)| | \xi_p=0] \phi_{\breve{\xi}_{\phi(p)}}(0) \; \nu(dp). \\
\end{aligned}
$$
with
\begin{equation}
  \label{eq:jacobian}
\bar{J}_{p,ij} =  \omega_j(\nabla_{\omega_i}\xi)_{p}
\end{equation}

The generality of the formula seems somewhat remarkable, though it hides many
nitty gritty details as many such formulae do. The only difference between the formula in
\cite{RFG} for counting critical points of a real-valued function is the $\cH$ connection in
\eqref{eq:jacobian}. For counting
critical points, the connection is the Levi-Civita connection of the induced metric. The intensity
is completely coordinate free and does not depend on the choice of frame.

\subsection{Special case: Gaussian but $E$ arbitrary}

When $\zeta$ are Gaussian, then the joint law of $(\bar{J}_p,\xi_p)$ is of course Gaussian and, by construction of
the connection
$\bar{J}(\xi)_p$ is independent of $\xi_p$. In general, unless $E$ is $T(M)$ or $T^*(M)$ there is no
special Riemannian metric associated to $\cH$. In this case, the Kac-Rice formula is perhaps better interpreted
as an alternating $d$-form (Lemma 2.4 of \cite{EulerCharManifolds}).
Still, we can pick our favorite Riemannian measure and work out the intensity
with respect to its Riemannian measure.

Importantly, Gaussianity implies that
the density $\phi_{\breve{\xi}_t}(0)$ is invariant to choice of orthonormal frame:
$$
\phi_{\breve{\xi}_t}(0) = (2\pi)^{-d/2} \exp\left(-\frac{1}{2} g(\mu_p, \mu_p) \right)
$$

Fixing a set of orthonormal vector fields $\{X_1,\dots, X_d\}$ for our favorite Riemannian metric on $M$ we could
write the intensity as
$$
\begin{aligned}
\E \left[\{p \in B: \xi_p=0\} \right] &= (2 \pi)^{-d/2}\int_{B} \E[|\det(\check{J}_p)|]  \exp\left(-\frac{1}{2} g(\mu_{p}, \mu_{p}) \right) \nu(dp). \\
\end{aligned}
$$
with
$$
\check{J}_{p,ij} =  \omega_j(\nabla_{X_i}\xi)_{p}.
$$
This intensity is coordinate free in that it does not depend on the choice of $\omega_j$'s or $X_i$'s.

\subsection{Very special case: Gaussian and $E$ is $T(M)$ or $T^*(M)$}

In this case, as noted above we can take $X_j=\omega_j$ (properly interpreted) and the
formula is very compact:
$$
\begin{aligned}
\E \left[\{p \in B: \xi_p=0\} \right] &= (2\pi)^{-d/2} \int_{B} \E[|\det(\bar{J}_p)|]  \exp\left(-\frac{1}{2} g(\mu_{p}, \mu_{p}) \right) \nu(dp). \\
\end{aligned}
$$
{\bf 
The only difference from this formula and the one for computing
the critical point intensity of a real-valued Gaussian process is the connection seen in $\bar{J}$ in \eqref{eq:jacobian}. Above,
$g$ would genuinely be a Riemannian metric. As we only assume $\mu \in H$ (and we've done all this work), this is
the connection which we'll use when doing coordinate free calculus for this intensity. The connection
may or may not be the Levi-Civita connection. This doesn't matter for Taylor series as all we will use is the
fact that it determines a parallel transport. One more related comment, for Riemannian manifolds with
the Levi-Civita connection there were natural curves to use for parallel transport, i.e. geodesics. Well,
we have a Riemannian metric too so there are natural curves for Taylor series to use for parallel transport. The parallel transport we do may not be the same as if it were the Levi-Civita connection but that doesn't matter. We would have to rewrite a few things in the Taylor series notes as I used the geodesic property, but that would be in paper \# 2 in any case...
}

\section{Measures bundles: computing integrals within and across fibers}

\jt{I feel some of this stuff must be written somewhere, though not for Gaussian densities. I know
  people who do stochastic analysis on manifolds study regularity of the heat kernel which is kind
  of similar. Not sure where I'd find it. This seems one sensible way to do things.}

\newcommand{\cJ}{\mathcal{J}}

In order to compute the Kac-Rice intensity one needs to evaluate the above expectation. This calculation
may of course be quite subtle. The matrix $\breve{J}_p$ is random and depends on our choice of frames even though it is indeed tensorial in the arguments $\partial t_i$ and $\omega_j$. It is more natural to consider
$\breve{\cJ} \in \Gamma(T^*(M) \otimes H)$ with
$$
\breve{J}_{ij,p} = \breve{\cJ}(\partial t_i, \omega_j)_p.
$$

This is of course a random section of $\Gamma(T^*(M) \otimes H)$ hence there is a map
$p \to {\cal P}_p(T_p^*M \otimes H_p)$ with ${\cal P}_p$ the set of probability measures
on $T_p^*M \otimes H_p$. These of course form a bundle ${\cal P}(T^*M \otimes H)$.

Given that $H_p$ has a metric there is a natural Hausdorff measure on $H_p$ while we may
pick a Riemannian  metric on $M$ so that $T_p^*M$ inherits its own natural Hausdorff measure.
In this case, we can consider  the subset ${\cal P}^{\infty}(T^*M \otimes H)$, the bundle  of probability measures
that have smooth densities with respect to the induced measure on $T_p^*M \otimes H_p$.

While we have made this construction for random sections of a specific bundle, similar ones can be made for other tensor products of $H$ and $T(M)$.
Let's consider first how to describe the law of $\xi$.
Define $\mathbb{R}^{\cH}$ to be the bundle of smooth functions $p \to \R^{H_p}$ generated by functions of the form
$$
a(X)_p = \bar{a}(\alpha_{1}(X)_p, \dots, \alpha_j(X)_p), \qquad \alpha_1, \dots, \alpha_j \in \cH^*, \bar{h}:\R^j \to \R
$$
That is, each function is determined by a set of $j$ sections of $\cH^*$ and a fixed function $\bar{a}$.

Let ${\cal M}_p(H_p) \supset {\cal P}_p(H_p)$ denote the set of measures on $H_p$ and its corresponding
smooth version ${\cal M}^{\infty}_p(H_p)$. We can consider ${\cal M}^{\infty}(H)$ as a bundle.
Given a section $m$ of this bundle and a section $a$ of $\mathbb{R}^{\cH}$ we 
can define the pairing
$$
m(a)_p = \int_{H_p} \bar{a}(\alpha_{1,p}(h_p), \dots, \alpha_{j,p}(h_p)) m_p(dh_p)
$$
with $dh_p$ the natural Hausdorff measure.

\jt{After looking at this more, we probably want to pullback $\gamma(t) \to p$... will look similar.}

Given a curve $\gamma:(-\epsilon,\epsilon) \to M$ with $\gamma(0)=p$ we can define
the parallel pushforward of $m$ as
$m_{p \to \gamma(t)} \in {\cal M}_{\gamma(t)}(H_{\gamma(t)})$
with
$$
\begin{aligned}
m_{p \to \gamma(t)}(a_{\gamma(t)}) &= \int_{H_{\gamma(t)}} \bar{a}(\alpha_{1, \gamma(t)}(h_{\gamma(t),p}), \dots, \alpha_{j,\gamma(t)}(h_{\gamma(t),p})) m_{p}(dh_p) \\
&= \int_{H_{\gamma(t)}} \bar{a}(\alpha_{1, \gamma(t)}(u), \dots, \alpha_{j,\gamma(t)}(u)) J_{p\to\gamma(t)} m_{\gamma(t)}(du) \\
&= J_{p\to\gamma(t)} \cdot m_{\gamma(t)}(a_{\gamma(t)})
\end{aligned}
  $$
where $h_{\gamma(t)}=P_{p \to \gamma(t)}h_p$ the parallel transport of $h_p$ to $h_{\gamma(t)}$ along $\gamma$ and
we have made the change of variables $u=P_{p \to \gamma(t)}h_p$. The variable
of integration in the second line doesn't include a subscript $\gamma(t)$ but it need not. The domain
is clear, as is the measure -- $u$ is simply a variable of integration. In the expression above, $m_p$ is pushed forward under the parallel transport map so that we can then integrate functions
over $H_{\gamma(t)}$.

The Jacobian \jt{(or its reciprocal ??)} is given by
$$
\begin{aligned}
  J_{p \to \gamma(t)}^2 &= \det(g_p(\omega_{i,\gamma(t)}, P_{p \to \gamma(t)}\omega_{j,p})), u \in H_{\gamma(t)}
  &= 1 + t \cdot \sum_{i=1}^d g(\nabla_{\dot{\gamma}(0)}\omega_i, \omega_i)_p + O(t^2)
\end{aligned}
$$
for any set of orthonormal frames on $H^*$. 

\jt{The $J_{p \to \gamma(t)}$  will be something like $\det(I + t V_p)$ -- a determinant like volume of tubes, fun!}

We have thus defined a mechanism that allows us to transport the pairing on ${\cal M}(H)$ and $\R^H$, meaning we can
meaningfully differentiate integrals of functions in $\R^{\cH}$ so that we might compute Taylor expansions along $\gamma$.
In the Riemannian case, recall that the curves by naturally taken to be geodesics so the above can be used to get
a relative error term that, to first order, will be an odd function.

Differentiating the intergal fully will obviously depend on the set of frames the densities but conceptually is not
too bad now: we can use the connection. These are the kind of calculations we were doing for the
coordinate free case so far (or the same in coordinates).
 That is, we can compute
$$
\begin{aligned}
  \lim_{t \downarrow 0} \frac{1}{t}(m_{\gamma(t)}(a_{\gamma(t)}) - m_p(a_p)) &=
\lim_{t \downarrow 0} \frac{1}{t}  \left(m_{\gamma(t)}(a_{\gamma(t)}) - m_{p \to \gamma(t)}(a_{\gamma(t)}) +  m_{p \to \gamma(t)}(a_{\gamma(t)}) - m_p(a_p)\right)
  
\end{aligned}
$$

\end{document}

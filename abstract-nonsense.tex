\documentclass{article}

\input{../preamble.sty}
\usepackage{lmodern}

\newcommand{\ag}[1]{{\bf{{\red{[{AG: #1}]}}}}}
\newcommand{\jt}[1]{{\bf{{\red{[{JT: #1}]}}}}}
\newcommand{\InnerProduct}[2]{\langle #1,#2 \rangle}
\newcommand{\Norm}[1]{\|#1\|}
\newcommand{\bP}{\mathbb{P}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\M}{\mathbb{M}}
\newcommand{\V}{\mathbb{V}}
\newcommand{\br}{{\bf r}}
\newcommand{\bs}{{\bf s}}
\newcommand{\bt}{{\boldsymbol t}}
\newcommand{\bH}{{\boldsymbol H}}
\newcommand{\Newton}{\mathrm{Newton}}
\newcommand{\DummyField}{{\tt f}}
\newcommand{\DummyGradient}{{\bf g}}
\newcommand{\InformationMatrix}{{\boldsymbol J}}
\newcommand{\lin}{\mathrm{lin}}
\newcommand{\ind}{\perp\!\!\!\!\perp} 
\newcommand{\Exp}{\mathrm{Exp}}

\newcommand{\RandomField}{Y}
\newcommand{\bLambda}{{\boldsymbol \Lambda}}
\newcommand{\bGamma}{{\boldsymbol \Gamma}}
\newcommand{\Err}{\mathrm{Err}}
\newcommand{\bQ}{{\boldsymbol Q}}
\newcommand{\bJ}{{\boldsymbol J}}
\newcommand{\bV}{{\boldsymbol V}}
\newcommand{\bI}{{\boldsymbol I}}
\newcommand{\bC}{{\boldsymbol C}}
\newcommand{\convweak}{\overset{d}{\to}}

\newcommand{\appropto}{\mathrel{\vcenter{
			\offinterlineskip\halign{\hfil$##$\cr
				\propto\cr\noalign{\kern2pt}\sim\cr\noalign{\kern-2pt}}}}}

\renewcommand{\thealgorithm}{\arabic{algorithm}}
\newcommand{\randsec}{\xi}
\newcommand{\linprocess}{\mathring{\randsec}}
\newcommand{\meansec}{\bar{\mu}}

\title{ {\bf Inference for Local Maxima of a Gaussian Random Field} \\ Abstract nonsense: random sections, zeros, Kac-Rice and Slepian}

\begin{document}

	\maketitle
	\RaggedRight

\section{A dose of abstract nonsense}

In this bit of abstract nonsense, we're going to discuss smooth random
sections of a vector bundle $\pi:E \to M$ (generalization of smooth random
fields) and associated probabilistic constructs. As in the case of a random field, a random section can
be viewed as a map $\randsec:\Omega \to \Gamma(E)$, i.e. a map from a probability space to smooth sections of $E$.
We're going to work with just $C^{\infty}$ for now, as the point is to see what tools are in the toolbox.
We'll assume the existence of $\bar{\nabla}$, a base connection on $E$. The map $\randsec$ will determine
its own connection as in the case of a real-valued random field on $M$, the base connection is just to
ensure we have some notion of differentiating sections, though it is not strictly necessary.

\subsection{Canonical example}

Pick a set $\{V_1, \dots, V_n\} \in \Gamma(E)$, i.e. a set of sections of the dual bundle $E$ and
a random vector $\bar{\zeta}:\Omega \rightarrow \mathbb{R}^n$ and define, for any $\alpha_p \in E_p^*$
\begin{equation}
  \label{eq:process}
\alpha_p(\randsec(\omega)) = \sum_{i=1}^n \bar{\zeta}_i(\omega) \cdot \alpha(V_i)_p.
\end{equation}
The mean of $\randsec$ is clearly
\begin{eqaution}
  \label{eq:meansec}
\meansec = \sum_{i=1}^n \E[\bar{\zeta}_i] \cdot V_i.
\end{equation}
If $\bar{\zeta}_i$ are Gaussian this would of course be a smooth Gaussian section of $E$, though
the construction above doesn't require Gaussianity.

As for random fields, there is an associated RKHS. In this case, the covariance kernel is a map $R:E^* \times E^* \to \R$ determined by
$$
R(\alpha_p, \bar{\alpha}_q) = \text{Cov}(\alpha_p(\randsec), \bar{\alpha}_q(\randsec)), \qquad \alpha_p \in F_p, \bar{\alpha}_q \in F_q.
$$
The corresponding  RKHS is a subspace of $\Gamma(E)$ with witness functions
$$
\langle R_{\alpha_p}, R_{\bar{\alpha}_q} \rangle_{\cH} = R(\alpha_p, \bar{\alpha}_q).
$$
The basic function in the RKHS takes the form
$$
h = \sum_j c_j R_{\alpha_{p_j}}   \in \Gamma(E)
$$
defined by
$$
h(\bar{\alpha})_q = \sum_j c_j R(\alpha_{p_j}, \bar{\alpha}_q)
$$
with the reproducing property following
$$
\langle R_{\alpha_p}, R_{\bar{\alpha}_q} \rangle = R(\alpha_p, \bar{\alpha}_q).
$$

A different, but equivalent way to define a random section of $E$ is as a real valued process $\linprocess:\Omega \times E^* \rightarrow \R$ satisfying
\begin{equation}
  \label{eq:alternate:construction}
\linprocess(\alpha_p + \bar{\alpha}_p) = \linprocess(\alpha_p) + \linprocess(\bar{\alpha}_p).
\end{equation}
Thus, defining any process of the form $\linprocess$ on $E^*$ determines a random section of $E$ via
$$
\randsec(\alpha)_p = \linprocess(\alpha_p).
$$

\newcommand{\ONF}{\eta}

The RKHS also determines a smooth (possibly degenerate) metric on $E^*$:
$$
g_p(\alpha_p, \bar{\alpha}_p) = \text{Cov}(\alpha_p(\randsec), \bar{\alpha}_p(\randsec)).
$$
There exists a subspace $H^*_p \subset F^*_p$ on which $g_p$ is non-degenerate. If the metric
is degenerate we'll make the assumption the spaces $(H_p)_{p \in M}$  form a sub-bundle $H^*$ of $E^*$ of some rank $d$. Let $H$ denote its dual, which we can and will identify with $H^*$ through the metric on $H^*$. Hence,
in what follows we simply refer to $H$.
With this metric on $H \subset E$ we can pick pick an orthonormal frame $(\ONF_1, \dots, \ONF_d)$ on $H$ and can
now write
\begin{equation}
  \label{eq:process:frame}
\randsec_p = \sum_{i=1}^d \ONF_{i,p}(\randsec) \ONF_i.
  \end{equation}

\subsection{Gaussian case}

In the case $\bar{\zeta}$ are mean 0 and Gaussian one can take any orthonormal basis
$(\varphi_i)$ of the RKHS along with IID $\zeta_i \sim N(0,1)$ defined above and realize the law $\randsec$ as
\begin{equation}
  \label{eq:KL}
\randsec(\omega) \overset{D}{=} \sum_{i=1}^n \zeta_i(\omega) \varphi_i + \meansec.
\end{equation}
That is, for $\alpha_p \in H_p^*$
$$
\alpha_p(\randsec(\omega)) = \sum_{i=1}^n \zeta_i(\omega) \alpha(\varphi_i)_p + \alpha_p(\meansec).
$$

\subsubsection{A few practical (?) examples}

Let $f$ be a real-valued Gaussian field on $M$ and set $\randsec_p = df_p$. This is a random section of $T^*(M)$. Shortly,
we'll want to discuss how the laws and intensities related to $\randsec$ and its zeros vary so that we might make
sense of asymptotic analysis. 

Consider the following process on $T^*(M \times \R)$: given $(X_{t,y}, b_{t,y}) \in T_t M \oplus T_y \R$ set
$$
\linprocess_{t,y} = df_t(X_{t,y}) + b_{t,y} \cdot (f_t - y).
$$
As this is a real valued process on $T(M \times \R)$ satisfying the required linearity, by our remark
\eqref{eq:alternate:construction} $\linprocess$ extends to a random section of $T^*(M \times \R)$. Zeros of
this process determine the intensity for critical points and their values.

Finally, given two real-valued processes $f$ and $\bar{f}$ consider a process on $T^*(M \times M)$ determined as follows: given $(X_{p,\bar{p}}, \bar{X}_{p,\bar{p}}) \in T_pM \oplus T_{\bar{p}}M$
set
$$
\bar{\zeta}_{(X_{p,\bar{p}}, \bar{X}_{p,\bar{p}})}(X_{p,\bar{p}}, \bar{X}_{p,\bar{p}}) = df_p(X_{p,\bar{p}}) + d\bar{f}_{\bar{p}}(\bar{X}_{p,\bar{p}}).
$$ If $f=\bar{f}$ then zeros of the above counts pairs of critical
points. By extending to $T^*((M \times \R) \times (M \times \R))$ as
our second example above we see that zeros of this process determine
the intensity for pairs of critical points and their values.

\section{Differentiation}

Given the base connection $\bar{\nabla}$ on $E$, we can clearly define
$$
\bar{\nabla}_X\randsec(\omega) = \sum_i \zeta_i(\omega) \bar{\nabla}_X \varphi_i.
$$
This is certainly well-defined if the RKHS is finite-dimensional. There is, however, a more natural
connection to consider.

\subsection{The ${\cal H}$ connection $\nabla^{\cal H}$}

The RKHS {\em almost} induces a connection $\nabla=\nabla^{\cH}$ on $\Gamma(E)$  in a canonical fashion.
It induces a connection defined on $\cH \subset \Gamma(E)$.
Fix a curve $\gamma:(-\epsilon,\epsilon) \to M$ with $\gamma(0)=p, \dot{\gamma}(0)=X_p$
and consider sections $\alpha \in \Gamma(H^*)$ of the form
$p \mapsto R_{\alpha_p} \in F_p, \alpha_p \in H^*_p$.
We first differentiate the curve $R_{\alpha} \circ \gamma$:
\begin{equation}
\dot{R}_{\alpha} = \frac{d}{dt} R_{\alpha} \circ \gamma(t) \biggl|_{t=0} = \lim_{t \to 0} \frac{1}{t} \left[ R_{\alpha(\gamma(t))} - R_{\alpha(0)}\right] \in {\cal H}.
\end{equation}
We then set
$$
\nabla_{X_p}R_{\alpha} = \dot{R}_{\alpha} - P(\dot{R}_{\alpha}, \text{span}(\dot{R}_{\bar{\alpha}_p}, \bar{\alpha}_p \in F_p^*)).
$$
That is, $\nabla_{X_p}R_{\alpha}$ is the residual after projecting $\dot{R}_{\alpha}$ onto the subspace of ${\cal H}$ spanned by the fiber $F_p$.
This connection can therefore be extended to all of ${\cal H}$ in a natural fashion.
Formally, this connection is not defined for any section as we've only defined it on $\cH$. By Riesz
representation,
it is also well defined on $\cH^*$. This is not too worrying as the main use for this connection is to define pathwise derivatives of $\randsec$ which only require
${\cal H}$. In turn this allows us to define
a pathwise derivative $\nabla_{X_p}\randsec$. By construction, we will have $\nabla_{X_p}\randsec$ is orthogonal
to $\alpha_p(\randsec)$ for all $\alpha_p \in H_p^*$.

This connection is clearly not the same as the base connection, nor
does it even depend on $\bar{\nabla}$ in any way. We can realize this pathwise derivative by
taking any orthonormal frames $(\ONF_{j})$ in $\Gamma(H^*)$:
\begin{equation}
\label{eq:pathwise:1}
(\nabla_X\randsec)_p = (\bar{\nabla}_X\randsec)_p - \sum_{i=1}^d \text{Cov}((\bar{\nabla}_X\randsec)_p, \ONF_{i,p}(\randsec))
 \ONF_{i,p}(\randsec)
\end{equation}

This can be checked by using the Karhunen-Lo\'eve expansion
\eqref{eq:KL} for the right hand side and verifying that the
covariance of this random variable with any other linear functional of
$\randsec$ is equal, through the usual Paley-Wiener map ${\cal I}:{\cal H}
\to L^2(\Omega)$, to the corresponding inner products on ${\cal
  H}$. In fewer words, in the Gaussian case, the right hand side can be written
\begin{equation}
  \label{eq:pathwise:2}
(\nabla_X\randsec)_p(\alpha) = {\cal I}(\dot{R}_{\alpha})(\omega) + (\nabla_X \meansec)_p
\end{equation}
When $\zeta$ are not Gaussian, ${\cal I}$ is still defined, at least for finite sums.

\subsection{Is it a Levi-Civita connection?}

When $H$ is $T(M)$ or $T^*(M)$ we see that $\cH$ induces (subject to non-degeneracy) a metric on
$H^*$ (and, through identification with its dual on $H$).
It is therefore a Riemannian metric. We have further associated a
connection to $\cH$. It is natural to ask if this connection is the Levi-Civita connection
of this Riemannian manifold. That is, is it compatible with the metric and torsion free.

In broad generality, the connection $\nabla$ is compatible with the metric on $H$.
To see this, let's assuming for the moment that $\meansec=0$ below so we can write $\E$ instead of $\Cov$.
For any vector field $X$ and sections $\omega, \bar{\omega} \in \cH$:
$$
\begin{aligned}
  X(g(\omega, \bar{\omega}))_p &= X(\E[\omega(\randsec) \bar{\omega}(\randsec)])_p \\
  &= \E[X(\omega(\randsec))_p \cdot \bar{\omega}(\randsec)_p + \omega(\randsec)_p \cdot X(\bar{\omega}(\randsec))_p] \\
&  = \E\left[\left((\nabla_X\omega)(\randsec)_p + \omega (\nabla_X\randsec)_p\right) \bar{\omega}(\randsec)_p\right] + \E\left[\omega(\randsec)_p \left((\nabla_X\bar{\omega})(\randsec)_p + \bar{\omega} (\nabla_X\randsec)_p\right) \right] \\
  &= \E\left[(\nabla_X\omega)(\randsec)_p \bar{\omega}(\randsec)_p\right] + \E\left[\omega(\randsec)_p (\nabla_X\bar{\omega})(\randsec)_p \right] \\
  &= g(\nabla_X\omega, \bar{\omega})_p + g(\omega, \nabla_X\bar{\omega})_p.
\end{aligned}
$$
We now resume assuming that $\meansec \neq 0$.

It is not clear, nor will it be important in what follows to establish that $H$ is the Levi-Civita
connection of this metric.

\subsection{Higher order derivatives}

We can write the connection $\nabla$ in terms of covariant derivatives
$$
{\nabla} \randsec(\omega) = \sum_i \zeta_i(\omega) \nabla \varphi_i \in \Gamma(T^*M \otimes H).
$$
The left hand side is our definition of the pathwise derivative from \eqref{eq:pathwise:2}.  The right
hand side is mathematically valid as $\varphi_i \in {\cal H}$ so we can define $\nabla_X \varphi_i$ as we did
$\nabla_XR_{\omega}$, extended to linear combinations in the usual fashion.

Higher order covariant derivatives can be similarly defined
$$
\nabla^k \randsec(\omega) = \sum_i \zeta_i(\omega) \nabla^k \varphi_i \in \Gamma(T^*M^{\otimes k} \otimes H).
$$

\section{Kac-Rice intensity}

\newcommand{\coordchart}{\mathfrak{t}}

Let $\pi:H \to M$ is a vector bundle of rank $d$ on a $q \geq d$-dimensional manifold $M$ and $\randsec$
a smooth random section of $H$. If we restrict $\randsec$ to a $d$-dimensional
submanifold $N \subset M$, under standard non-degeneracy assumptions zeros of $\randsec$ will be isolated.
We can then try to compute the intensity function of the zeros of $\randsec$.

Pick an orthonormal frame $(\ONF_1, \dots, \ONF_d) \in \cH^*$ and a chart
$\coordchart:U \to \R^d$ so that
$$
\breve{\randsec}_t = (\randsec(\ONF_1)_{\coordchart^{-1}(t)}, \dots, \randsec(\ONF_d)_{\coordchart^{-1}(t)}): \R^d \to \R^d.
$$
The standard Kac-Rice formula on $\R^d$ yields, for $B \subset U$
$$
\begin{aligned}
\E \left[ \#\{p \in B: \randsec_p=0\} \right] &= \int_{\coordchart(B)} \E\left[|\det(J_t)| \bigr | \breve{\randsec}_t=0 \right] \phi_{\breve{\randsec}_t}(0) \; dt \\
\end{aligned}
$$
where
$$
\begin{aligned}
  (J_t)_{ij} &= \frac{\partial \breve{\randsec}_t}{\partial t_i} \\
  &= (\ONF_j(\nabla_{\partial t_i}\randsec))_{\coordchart^{-1}(t)} + (\nabla_{\partial t_i} \ONF_j)(\randsec)_{\coordchart^{-1}(t)}. \\
\end{aligned}
$$
As this the conditional expectation sets $\randsec_p$ to 0, we can rewrite this as
$$
\begin{aligned}
\E \left[\# \{p \in B: \randsec_p=0\} \right] &= \int_{\coordchart(B)} \E \left[|\det(\breve{J}_{\coordchart^{-1}(t)})| \bigr | \randsec_{\coordchart^{-1}(t)}=0 \right] \phi_{\breve{\randsec}_t}(0) \; dt \\
\end{aligned}
$$
with
$$
\begin{aligned}
  (\breve{J}_p)_{ij} &= \ONF_j(\nabla_{\partial t_i}\randsec)_{p}
\end{aligned}
$$
which is tensorial in $\partial t_i$ and $\ONF_j$.


The integral above can be split as
$$
\begin{aligned}
\E \left[\# \{p \in B: \randsec_p=0\} \right] &= \int_{\coordchart(B)} \E \left[1_{\{\det(\breve{J}_{\coordchart^{-1}(t)}) > 0\}}\det(\breve{J}_{\coordchart^{-1}(t)})| \bigr | \randsec_{\coordchart^{-1}(t)}=0 \right] \phi_{\breve{\randsec}_t}(0) \; dt \\
& - \int_{\coordchart(B)} \E \left[1_{\{\det(\breve{J}_{\coordchart^{-1}(t)}) < 0\}}\det(\breve{J}_{\coordchart^{-1}(t)})| \bigr | \randsec_{\coordchart^{-1}(t)}=0 \right] \phi_{\breve{\randsec}_t}(0) \; dt \\
\end{aligned}
$$
Following \cite{ECmanifolds,Federer} we can express $\det(\breve{J})_p$ as $\text{Tr}(\breve{\cal J}^d)_p/d!$
with $\breve{\cal J}^d_p \in \Lambda^d(T^*_pM) \otimes \Lambda^d(H_p)$ with the product being
the commutative product on double forms. In \cite{ECmanifolds,Federer} the two spaces in the alternating
forms were the same, but the double product can still be defined, as can its trace though it would have to be
a signed trace. Fixing the frames on $T(M)$ and $H^*$ resolves the sign of $\text{Tr}$ on
$\Lambda^d(T^*(M)) \otimes \Lambda^d(H)$. Hence, the
Kac-Rice intensity can be written (having fixed the frames) as
$$
\begin{aligned}
\E \left[\# \{p \in B: \randsec_p=0\} \right] &= \frac{1}{d!} \int_{\coordchart(B)} \biggl( \E \left[1_{S^+_p} \text{Tr}(\breve{\cal J}_p^d) \bigl| \randsec_p=0\right]   - \E \left[1_{S^-_p} \text{Tr}(\breve{\cal J}_p^d) \bigl| \randsec_p=0\right] \biggr) \phi_{\breve{\randsec}_t}(0) \; dt.
\end{aligned}
$$
with $S^{\pm}_p$ the events that fix the sign of the determinant.
Given $\breve{J}$ evaluated in other frames on $T(M)$ or $H^*$ we can compute the sign within the original frame by computing the sign of the corresponding changes on $T(M)$ and $H^*$ separately.
In the case $E=T(M)$ or $E=T^*(M)$ so that
it makes sense to say $\breve{\cal J}^d_p \in \Lambda^d(T^*_pM) \otimes \Lambda^d(T^*_pM)$, we can further partition the expectation over events where the index of $\breve{\cal J}^d_p$ is fixed.

\section{Sign definite heuristic (aka high curvature heuristic)}

If $\breve{\cal J}_p$ is stochastically large in a region of parameter space its
sign will effectively be constant and not change with perturbations
of $\randsec$. Without loss of generality, we can assume that we have chosen frames so that its sign is positive.
In this case, the Kac-Rice intensity can be approximated as
\begin{equation}
  \label{eq:sign:definite}
\begin{aligned}
\E \left[\# \{p \in B: \randsec_p=0\} \right] & \approx \E \left[\{p \in B: \randsec_p=0, \text{sign}(\breve{\cal J}_p)=+1\} \right] \\
& \approx \frac{1}{d!} \int_{\coordchart(B)} \E \left[ \text{Tr}(\breve{\cal J}_p^d) \bigl| \randsec_p=0\right] \phi_{\breve{\randsec}_t}(0) \; \; dt
\end{aligned}
  \end{equation}

The function $\det(\breve{J}_p)$ can be viewed as the evaluation of a form on $\Lambda^d(T^*N) \otimes \Lambda^d(H)$
a subset of the algebra of double forms
$$\Lambda^{*,*}(T^*N, H) = \oplus_{k} \Lambda^{k}(T^*N) \otimes \Lambda_{k}(H).$$
This algebra is equipped with a commutative product on each fiber
$$
(\gamma_1 \otimes \alpha_1)_p \cdot (\gamma_2 \otimes \alpha_2)_p = (\gamma_1 \wedge \gamma_2)_p \otimes (\alpha_1 \wedge \alpha_2)_p.
$$
When $T^*_pN = H_p$ then the trace is defined on $\Lambda^{*,*}(T^*_pN, T^*_pN)$ and $T^*_pN$ is equipped
with an inner produce, we can define
$$
\text{Tr}(\gamma_p \wedge \bar{\gamma}_p) = \langle \gamma_p, \bar{\gamma}_p \rangle.
$$
Continuing with the assumption $T^*_pN=H_p$ any $A \in \Lambda^1(T^*_pN) \wedge \Lambda^1(T^*_pN)$
can be represented as a matrix $\bar{A}$ by picking an orthonormal basis
and for $j \leq \text{dim}(T^*_pN)$:
$$
\text{detr}_j(\bar{A}^j_p) = \frac{1}{j!} \text{Tr}(A^j_p).
$$

When $T_p^*N \neq H_p$ then there is no connection between orthonormal bases
of $T_p^*N$ and $H_p$ hence the best we could hope for is that the
map $\text{Tr}$ is determined up to sign. That is, swapping the order of  $(\ONF_1, \dots, \ONF_d)$ may change the sign of the determinant. One can detect a sign change for a different orthonormal basis $(\bar{\ONF}_1, \dots, \bar{\ONF}_d)$ by
checking the sign of
$$
\text{det}(\langle \ONF_i, \bar{\ONF}_j \rangle).
$$
Similar sign changes can be detected in a change of coordinates on $N$. Of course, locally (or globally for a choice of orthonormal frames) the sign
cannot change as both sets of vectors span $T_p^*N$ or $H_p$, respectively.

\subsection{Special case: $H=T(N)$ or $H=T^*(N)$}

In this case, as $\cH$ determines a metric on $H$, this will be a Riemannian
metric. The implication
here means that the $\ONF_j$'s can therefore be interpreted as an orthonormal frame of vector fields with
this metric. \jt{check def of index to get sign correct below}
The tensorial aspect of $\breve{J}_p$ implies we can now compute this intensity
with respect to the Riemannian measure $\nu$. For $B \subset N$:
$$
\begin{aligned}
\E \left[\# \{p \in B: \randsec_p=0\} \right] &= \sum_{j=0}^d  \frac{(-1)^j}{d!} \int_{B} \E[1_{I_{j,p}} \text{Tr}(\bar{\cal J}_p^d) | \randsec_p=0] \phi_{\breve{\randsec}_{\phi(p)}}(0) \; \nu(dp). \\
\end{aligned}
$$
with $I_{j,p}$ the event the index of $\bar{\cal J}_p^d$  is $j$ and $\bar{\cal J}_p$ is the double
form related to the symmetric matrix \jt{should be symmetric by compatibility I think}
\jt{check index wording}
\begin{equation}
  \label{eq:jacobian}
\bar{J}_{p,ij} =  \ONF_j(\nabla_{\ONF_i}\randsec)_{p}.
\end{equation}
In the case of critical points of a real-valued function, this matrix is, in some sense, the second fundamental form
of $M$. Not sure exactly of how to interpret it here but it behaves like the second fundamental form. \jt{more details needed here perhaps}

In this case the sign-definite heuristic should probably be restated as index-definite heuristic in which
we assume one index dominates the others yielding
$$
\begin{aligned}
\E \left[\# \{p \in B: \randsec_p=0, \text{index}(\bar{\cal J}_p)=j\} \right] & \approx   \frac{(-1)^j}{d!} \int_{B} \E[ \text{Tr}(\bar{\cal J}_p^d) | \randsec_p=0] \phi_{\breve{\randsec}_{\phi(p)}}(0) \; \nu(dp). \\
\end{aligned}
$$

The formula hides several
nitty gritty details as many such formulae do. The only difference between the formula in
\cite{RFG} for counting critical points of a real-valued function is the $\cH$ connection in
\eqref{eq:jacobian}. For counting
critical points, the connection is the Levi-Civita connection of the induced metric. The intensity
is completely coordinate free and does not depend on the choice of frame, up to sign based on the choice of frame.

\section{Gaussian random sections}

So far, we have not explicitly made a Gaussian assumption, mostly because we have not
tried to explicitly compute any quantities. We now assume the $\zeta_i$

When $\zeta$ are Gaussian, then the joint law of $(\breve{J}_p,\randsec_p)$ is of course Gaussian and, by construction of
the connection
$\breve{J}(\randsec)_p$ is independent of $\randsec_p$. In general, unless $H$ is  $T(M)$ or $T^*(M)$ there is no
special Riemannian metric associated to $\cH$. 
Still, we can pick our favorite Riemannian measure and work out the intensity
with respect to its Riemannian measure.


Importantly, Gaussianity also implies that
the density $\phi_{\breve{\randsec}_t}(0)$ is invariant to choice of orthonormal frame:
$$
\phi_{\breve{\randsec}_t}(0) = (2\pi)^{-d/2} \exp\left(-\frac{1}{2} g_p(\meansec_p, \meansec_p) \right)
$$

Fixing a set of orthonormal vector fields $\{X_1,\dots, X_d\}$ for our favorite Riemannian metric on $M$ we could
write the intensity as
$$
\begin{aligned}
\E \left[\# \{p \in B: \randsec_p=0\} \right] &=  (2 \pi)^{-d/2}\int_{B} \E[1_{A^+_p} \text{Tr}(\check{\cal J}^d_p) - 1_{A^-_p} \text{Tr}(\check{\cal J}^d_p)]  \exp\left(-\frac{1}{2} g_p(\meansec_{p}, \meansec_{p}) \right) \nu(dp). \\
\end{aligned}
$$
with
$$
\check{J}_{p,ij} =  \ONF_j(\nabla_{X_i}\randsec)_{p}.
$$
This intensity is coordinate free in that it does not depend on the choice of $\ONF_j$'s or $X_i$'s.
Applying the sign-definite heuristic yields
$$
\begin{aligned}
  \E \left[\# \{p \in B: \randsec_p=0\} \right] & \approx  (2 \pi)^{-d/2}\int_{B} \E[ \text{Tr}(\check{\cal J}^d_p)]  \exp\left(-\frac{1}{2} g_p(\meansec_{p}, \meansec_{p}) \right) \nu(dp) \\
  &= (2 \pi)^{-d/2}\int_{B} \E[ \text{Tr}(\check{\cal J}^d_p)]  \exp\left(-\frac{1}{2} \sum_{i=1}^d \ONF_i(\meansec)_p^2\right) \nu(dp). \\
\end{aligned}
$$

When $\breve{J}_p$ is random and Gaussian, \cite{RFG} expresses
$\E[\text{detr}_j(\check{J}^j_p)]$ in terms of $\E[\check{ \cal J}_p]$ and $\E[\check{ \cal J}_p^2]$.
Therefore, having fixed the bases for the
left and right of $\check{J}_p$ and fixing the sign of $\det(\check{J}_p)$
it will be a Gaussian random matrix when $\randsec$ is Gaussian that can be viewed as the
$d$-th power of a $(1,1)$-double form. The tools
of \cite{RFG,ECmanifolds} can be used to evaluate the expectation of its
determinant. We continue to use the notation $\text{Tr}$.  \jt{We save this calculation for later: the second moment should be the curvature double form
for the $H$-connection.}

\subsection{Restriction of a random section}

Suppose $\bar{N} \subset N$ is an embedded submanifold of co-dimension $k \geq 1$. The process $\randsec$ on the bundle of rank
$d=\text{dim}(N)$ will generically not have any zeros in $\bar{N}$. If we could somehow naturally restrict
$\randsec$ to a bundle of rank $d-k$ then we would start to generically see zeros and could compute a
Kac-Rice intensity. Perhaps the simplest construction of a restriction of $\randsec$ comes from the representation
\eqref{eq:process:frame}. Given an orthonormal frame $(\ONF_1, \dots, \ONF_d)$ we can construct a restricted process
$\linprocess$ as
$$
\bar{\randsec}_p = \sum_{i=1}^{d-k} \ONF_i(\randsec) \ONF_i.
$$
Of course, the construction will depend on the vectors in our frame but will be natural in our examples. We see that
$\bar{\randsec}$ will be a random section of a $\bar{H}$ a subbundle of $H$ whose fibers are 
$\bar{F}_p = \text{span}(\ONF_{i,p}:1 \leq i \leq d-k).$ The mean of $\bar{\randsec}$ is of course
$$
\E[\bar{\randsec}_p] = \sum_{i=1}^{d-k} \ONF_i(\meansec)_p \ONF_{i,p}.
$$
Following through with the construction of  $\bar{H}$, we see that
$\bar{H}$ is the fiberwise projection of the $H$ connection onto the fibers $\bar{H}$.

When $\randsec$ is a Gaussian random section, $\bar{\randsec}$ will similarly be Gaussian. Its Kac-Rice
intensity with respect to Riemannian measure will take the form
\begin{equation}
  \label{eq:kac:rice:restriction}
\int_B \frac{1}{(d-k)!}\E[ \text{Tr}(\tilde{\cal J}_p^{d-k})] \exp\left(-\frac{1}{2} \sum_{i=1}^{d-k} \ONF_i(\meansec)_p^2\right) \bar{\nu}(dp)
\end{equation}
with $\bar{\nu}$ the Riemannian measure on $\bar{N}$.

Compare the above to the restriction of the Kac-Rice intensity of $\randsec$ to $\bar{N}$. In the exponent,
we note the difference
$$
-\frac{1}{2}\sum_{i=d-k+1}^d \ONF_i(\meansec)_p^2.
$$
The double forms $\tilde{\cal J}_p$ and $\check{\cal J}_p$ will differ fiberwise by the orthogonal projection of the
$H$ connection onto the normal space of $\bar{H}$.

\subsection{Example revisited}

Given a smooth real valued Gaussian field $f$ with mean
function $\mu_t=E[f_t]$. , consider our process on $T^*(M \times \R)$ with $\text{dim}(M)=d$
that computes
the intensity of critical points near $t$ of value $y$:
$$
\linprocess\left(X_{t,y}, b_{t,y} \frac{\partial}{\partial y} \right) =  df_t(X_{t,y}) + b_{t,y}(f_t - y) .
$$

The process $f$ determines a Riemannian metric on $M$. Take $(E_1, \dots, E_d)$ to be an orthonormal
frame on $M$ so that
$$
\linprocess(E_{1,t}, 0) \sim N((E_{i}\mu)_t, 1).
$$
To find a final vector for the $(d+1)$ frames, set
$$
Z_{t,y} = \frac{1}{\bar{\sigma}_t}\left( \sum_{i=1}^d \text{Cov}(f_t, (E_if)_t) E_{i,t}, \frac{\partial}{\partial y} \biggl|y \right)
$$
with
$$
\bar{\sigma}^2_t = \text{Var}(f_t|df_t).
$$

It's straightforward to check that
$$\text{Cov}(\linprocess(Z_{t,y}), \linprocess(0, E_{i,t})) = 0$$ and
$$
\text{Var}(\linprocess(Z_{t,y}))=1.
$$
Hence, the set $(E_1,\dots, E_d, Z)$ form an orthonormal frame for $H$.

We called the final vector field $Z_{t,y}$ as it computes a (conditional) $Z$ statistic to test the
hypothesis that the mean of $\bar{f}_t$ is $y$:
$$
Z_{t,y}(\randsec) = \frac{\bar{f}_t - y}{\bar{\sigma}_t}
$$
with
$$
\bar{f}_t = f_t - \sum_{i=1}^d (E_if)_t.
$$

Taking our submanifold $N$ to be  $M \times \R$ itself, 
the Kac-Rice intensity for the zeros of this process $\randsec$ involves the term
$$
Z_{t,y}(\mu)^2 + \|\nabla \mu_t\|^2.
$$

Let's now consider a restriction of $\randsec$: we simply remove $Z$ from our orthonormal frame. In this case,
the process $\bar{\randsec}$ is simply the differential (which can be identified with the gradient once
we have computed the metric):
$$
\bar{\randsec}_{t,y} = \sum_{i=1}^d (E_if)_t E_{i,t}.
$$
This process simply counts critical points of $f$ without tracking their values. In its Kac-Rice
intensity we will see the term
$$
\|\nabla \mu_t\|^2.
$$

The difference is the term $Z_{t,y}(\mu)^2$. \jt{This is the source of goldilocks!}

\section{Asymptotic analysis}

Suppose $p^* \in N$ is a point of interest around which we'd like to expand the Kac-Rice intensity for a
Gaussian $\randsec$, or perhaps a conditional derived from the intensity. For concreteness, let's use our
counting process that counts critical points of a real-valued $f$ along with their values. In this
case $p$ consists of a pair $(t,y)$ 

The conditional intensity for this process would fix $y$ at some value and inspect the joint intensity
in some ball around $B_{t^*}(r)$. Note that conditioning on $y$ is equivalent to conditioning on $\bar{Z}_{t,y}(\randsec)$, i.e. component of $\randsec$ we killed to construct this restriction.
We will have to expand the exponent
\begin{equation}
  \label{eq:mahalanobis1}
Z_{t,y}(\mu)^2 + \|\nabla \mu_t\|^2
\end{equation}
in $t$ keeping $y$ fixed. Following calculations we've seen in the constant variance case, under
the assumption that $\nabla \mu_{t^*}=0$, the gradient of the first term is 0 while
the Hessian of the second term is the ``sandwich'' form of the variance.
The term $Z_{t,y}(\mu)^2$ contributes its one linear term in its gradient and its Hessian is
also going to contribute. In the constant variance case, the gradient of $Z^2$ is 0 at $t^*$ for any $y$. For non-constant variance it simply may be non-zero.

Compare this to the intensity of critical points of $f$ without regard to value. It will only have the
term $\|\nabla \mu_t\|^2$.

An example codimension $k>1$ is the Kac-Rice intensity for critical points
on the boundary of a codimension one manifold $\partial M \subset M$ and their values. Without loss of generality
let $E_1$ be a normal vector (defined up to sign of course). The process
$\randsec$ remains the same with $H$ a bundle of rank $d+1$.

We now kill the $E_d$ term as well to get a rank $d-1$ bundle $\bar{H}$ and associated process
$\bar{\randsec}$. The Kac-Rice intensity of $\bar{\randsec}$ will be the intensity function of critical
points on $\partial M$ without tracking the value or the derivative in the normal direction.

We can now condition on $E(\randsec)_{t}$ as well as $Z_{t,y}(\randsec)$. This conditional intensity
will expand the same quantity \eqref{eq:mahalanobis1} which we rewrite as
$$
\begin{aligned}
  \label{eq:mahalanobis1}
  Z_{t,y}(\mu)^2 + \|\nabla \mu_t\|^2 &= Z_{t,y}(\mu)^2 + \sum_{i=1}^d E_i(\mu)_t^2 \\
  & = \left(Z_{t,y}(\mu)^2 + E_1(\mu)_t^2\right) + \sum_{i=2}^d E_2(\mu)_t^2.
  \end{aligned}
$$
The difference between the Kac-Rice intensity of the restriction and the conditional
intensity will be the term
$$
\left(Z_{t,y}(\mu)^2 + E_1(\mu)_t^2\right)
$$
which is some form of $\chi^2_2...$. The Goldilocks effect here will come
from the gradient and Hessian of the sum of these two terms.


\end{document}
